{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from pandas import read_csv\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "# Extra part for memory management\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Make_LSTM_SSN(train_index, val_index, test_index, Output_Type, state_condition='Stateless', shuffle='True', \n",
    "                     pred_hour=156, LSTM_hour=156, num_unit=240, num_epoch=1200, optimizer='Adam', loss_ftn='mean_squared_error'):\n",
    "    \n",
    "    if Output_Type is \"OneTime\" or Output_Type is \"StepUp\":\n",
    "        print(\"Output : \", Output_Type)\n",
    "    else:\n",
    "        print, 'You entered wrong Output_Type! Have to enter \"StepUp\" or \"OneTime\"'\n",
    "        sys.exit()        \n",
    "\n",
    "  \n",
    "    len_PRED = int(pred_hour)\n",
    "    len_LSTM = int(LSTM_hour)\n",
    "    \n",
    "    file_condition = str(LSTM_hour)+'LSTM' + str(LSTM_hour)+'Prediction'\n",
    "    \n",
    "    if len_PRED <= 0:\n",
    "        print(\"You entered wrong predction hour or peak hour\")\n",
    "        sys.eixt()\n",
    "    if len_LSTM <= 0:\n",
    "        print(\"You entered wrong LSTM hour or peak hour\")\n",
    "        sys.eixt()\n",
    "        \n",
    "        \n",
    "    if Output_Type is \"OneTime\":\n",
    "        allDataSet = read_csv('C:\\\\Users\\\\YKW\\\\GoogleDrive\\\\Study USB BackUp\\\\SSN\\\\SSN_LSTM_csv\\\\SNN_M_'+file_condition+'.csv', sep=',')\n",
    "    else:\n",
    "        if Output_Type is \"StepUp\":\n",
    "            allDataSet = read_csv('C:\\\\Users\\\\YKW\\\\GoogleDrive\\\\Study USB BackUp\\\\SSN\\\\SSN_LSTM_csv\\\\SSN_M_'+str(LSTM_hour)+'LSTM_1Prediction.csv', sep=',')\n",
    "    \n",
    "    allDataSet_size = len(allDataSet)\n",
    "                                  \n",
    "    \n",
    "    print(\"allDataSet: \", allDataSet.shape)\n",
    "    print(\"allDataSet_size: \", allDataSet_size)\n",
    "    print(\"allDataSet Type: \", type(allDataSet))\n",
    "    print(\"allDataSet_size Type: \", type(allDataSet_size))\n",
    "    \n",
    "    LSTM_count = np.arange(len_LSTM)+1\n",
    "    LSTM_count = LSTM_count* (-1)\n",
    "    LSTM_count = LSTM_count +len_LSTM+1\n",
    "    LSTM_title = []\n",
    "    for bi in range(len(LSTM_count)):\n",
    "        LSTM_title.append('b'+str(int(LSTM_count[bi])))\n",
    "        \n",
    "    pred_count = np.arange(len_PRED)\n",
    "    pred_title = []\n",
    "    for ai in range(len(pred_count)):\n",
    "        pred_title.append('a'+str(int(pred_count[ai])))\n",
    "        \n",
    "#    print(LSTM_title)\n",
    "#    sys.exit()\n",
    "    \n",
    "    LSTM_title1 = LSTM_title[0:30]\n",
    "    LSTM_title2 = LSTM_title[30:60]\n",
    "    LSTM_title3 = LSTM_title[60:90]\n",
    "    LSTM_title4 = LSTM_title[90:120]\n",
    "    LSTM_title5 = LSTM_title[120:133]\n",
    "    \n",
    "#    print(LSTM_title1)\n",
    "#    sys.exit()\n",
    "\n",
    "    \n",
    "    flux1 = allDataSet[LSTM_title1].values\n",
    "    flux2 = allDataSet[LSTM_title2].values   \n",
    "    flux3 = allDataSet[LSTM_title3].values   \n",
    "    flux4 = allDataSet[LSTM_title4].values\n",
    "    flux5 = allDataSet[LSTM_title5].values\n",
    "    \n",
    "    sys.exit()\n",
    "\n",
    "   \n",
    "    now_flux = allDataSet['a0'].values\n",
    "    now_Year = allDataSet['Year'].values\n",
    "    now_Mon = allDataSet['Mon'].values\n",
    "     \n",
    "    d_flux = np.array([flux])    \n",
    "    d_now_flux = np.array([now_flux])\n",
    "    d_now_Year = np.array([now_Year])\n",
    "    d_now_Mon = np.array([now_Mon])   \n",
    "  \n",
    "    d_flux = np.array(d_flux).reshape(allDataSet_size, len_LSTM,1)    \n",
    "    d_now_flux = np.array([d_now_flux]).reshape(allDataSet_size, 1)\n",
    "    d_now_Year = np.array([d_now_Year]).reshape(allDataSet_size, 1)\n",
    "    d_now_Mon = np.array([d_now_Mon]).reshape(allDataSet_size, 1)\n",
    "                                  \n",
    "    if Output_way is \"Onetime\":\n",
    "        pred_flux = allDataSet[pred_title].values\n",
    "        d_pred_flux = np.array([pred_flux])\n",
    "        d_pred_flux = np.array(d_pred_flux).reshape(allDataSet_size, len_PRED)\n",
    "                                  \n",
    "    \n",
    "                                  \n",
    "    def M_LSTM_Stateful(shapes):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(num_unit,batch_input_shape=shapes, stateful=True))\n",
    "        if Output_type is \"StepUp\":\n",
    "            model.add(Dense(1))\n",
    "        else:\n",
    "            if Output_type is \"OneTime\":\n",
    "                model.add(Dense(len_PRED))\n",
    "        model.summary()\n",
    "        return model\n",
    "            \n",
    "    def M_LSTM_Stateless(shapes):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(num_unit,input_shape=shapes, stateful=False))  # model.add(LSTM(num_unit,input_shape=shapes, return_sequences=True, stateful=False))\n",
    "        if Output_type is \"StepUp\":\n",
    "            model.add(Dense(1))\n",
    "        else:\n",
    "            if Output_type is \"OneTime\":\n",
    "                model.add(Dense(len_PRED))\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "    class PlotLosses(keras.callbacks.Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.i = 0\n",
    "            self.x = []\n",
    "            self.losses = []\n",
    "            self.val_losses = []\n",
    "\n",
    "            self.fig = plt.figure()\n",
    "\n",
    "            self.logs = []\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "            self.logs.append(logs)\n",
    "            self.x.append(self.i)\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            self.val_losses.append(logs.get('val_loss'))\n",
    "            self.i += 1\n",
    "            clear_output(wait=True)\n",
    "            plt.plot(self.x, self.losses, label=\"loss\")\n",
    "            plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "            plt.legend()\n",
    "            plt.show();\n",
    "            \n",
    "\n",
    "    if shuffle is 'True':\n",
    "        if state_conditon is \"Stateful\":\n",
    "            print('You can not set shuffle=\"True\" while state_condition is \"Stateful\"!')\n",
    "            sys.exit()\n",
    "        weightfileName = 'C:\\\\Users\\\\YKW\\\\GoogleDrive\\\\Study USB BackUp\\\\SSN\\\\SSN_LSTM_WEIGHT\\\\Layer1_shuffled_'+state_condition+'_'+Output_Way+'_LSTM_GOES15_pgt10_'+file_condition+'_ep'+str(num_epoch)+'_'+str(num_unit)+'units_WEIGHT'\n",
    "        testfileName = 'C:\\\\Users\\\\YKW\\\\GoogleDrive\\\\Study USB BackUp\\\\SSN\\\\SSN_LSTM_RESULT\\\\Layer1_shuffled_'+state_condition+'_'+Output_Way+'_TEST_'+file_condition+'_Proton_LSTM.csv'\n",
    "    else:\n",
    "        if shuffle is 'False':\n",
    "            weightfileName = 'C:\\\\Users\\\\YKW\\\\GoogleDrive\\\\Study USB BackUp\\\\SSN\\\\SSN_LSTM_WEIGHT\\\\Layer1_'+state_condition+'_'+Output_Way+'_LSTM_GOES15_pgt10_'+file_condition+'_ep'+str(num_epoch)+'_'+str(num_unit)+'units_WEIGHT'\n",
    "            testfileName = 'C:\\\\Users\\\\YKW\\\\GoogleDrive\\\\Study USB BackUp\\\\SSN\\\\SSN_LSTM_RESULT\\\\Layer1_'+state_condition+'_'+Output_Way+'_TEST_'+file_condition+'_Proton_LSTM.csv'\n",
    "            \n",
    "\n",
    "    plot_losses = PlotLosses()\n",
    "    \n",
    "    if state_condition is 'Stateful':\n",
    "        inputFluxShape = (1,len_LSTM, 1)\n",
    "        model = M_LSTM_Stateful(inputFluxShape)\n",
    "\n",
    "    else:\n",
    "        if state_condition is 'Stateless':\n",
    "            inputFluxShape = (len_LSTM,1)  \n",
    "            model = M_LSTM_Stateless(inputFluxShape)\n",
    "        else:\n",
    "            print(\"You enterd wrong state_condition!\")\n",
    "            sys.exit()\n",
    " \n",
    "\n",
    "    val_index  = train_index + val_index\n",
    "    test_index = val_index + test_index\n",
    "    \n",
    "    trainX = d_flux[:train_index]    \n",
    "    trainYear = d_now_Year[:train_index]\n",
    "    trainMon = d_now_Mon[:train_index]\n",
    "    \n",
    "    valX = d_flux[train_index:val_index]    \n",
    "    valYear = d_now_Year[train_index:val_index]\n",
    "    valMon = d_now_Mon[train_index:val_index]\n",
    "    \n",
    "#    testX = d_flux[val_index:test_index]    \n",
    "#    testYear = d_now_Year[val_index:test_index]\n",
    "#    testMon = d_now_Mon[val_index:test_index]\n",
    "                  \n",
    "    testX = valX\n",
    "    testYear = valYear\n",
    "    testMon = valMon\n",
    "    \n",
    "    if Output_type is \"StepUp\":\n",
    "            trainY = d_now_flux[:train_index]\n",
    "            valY = d_now_flux[train_index:val_index]\n",
    "#            testY = d_now_flux[val_index:test_index]\n",
    "            testY = valY\n",
    "    else:\n",
    "        if Output_type is \"OneTime\":\n",
    "            trainY = d_pred_flux[:train_index]\n",
    "            valY = d_pred_flux[train_index:val_index]\n",
    "#           testY = d_pred_flux[val_index:test_index]\n",
    "            testY = valY\n",
    "\n",
    "    \n",
    "    model.compile(loss=loss_ftn, optimizer=optimizer, metrics=['acc'])\n",
    "    \n",
    "    \n",
    "    if state_condition is 'Stateful':    \n",
    "        for epoch_idx in range(num_epoch):\n",
    "            if shuffle is 'True':\n",
    "                model.fit(trainX, trainY, epochs=1, batch_size=1, verbose=2, shuffle=True, validation_data=(valX, valY))\n",
    "                model.reset_states()\n",
    "            else:\n",
    "                if shuffle is 'False':\n",
    "                    model.fit(trainX, trainY, epochs=1, batch_size=1, verbose=2, shuffle=False, validation_data=(valX, valY))\n",
    "                    model.reset_states()\n",
    "            print(epoch_idx)\n",
    "    else:\n",
    "        if state_condition is 'Stateless': \n",
    "            if shuffle is 'True':\n",
    "                model.fit(trainX, trainY, epochs=num_epoch, batch_size=1400, verbose=2, shuffle=True, validation_data=(valX, valY))\n",
    "            else:\n",
    "                if shuffle is 'False':\n",
    "                    model.fit(trainX, trainY, epochs=num_epoch, batch_size=1400, verbose=2, shuffle=False, validation_data=(valX, valY))\n",
    "\n",
    "        \n",
    "    model_json = model.to_json()\n",
    "    with open(weightfileName + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(weightfileName + \".h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    json_file = open(weightfileName + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "    loaded_model.load_weights(weightfileName + \".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    loaded_model.compile(loss=loss_ftn, optimizer=optimizer, metrics=['acc'])\n",
    "    \n",
    "\n",
    "    f = open(testfileName, 'w')\n",
    "    f.write(Ouput_way+'_'+state_condition+'shuffle='+shuffle+'_'+str(num_epoch)+'epochs_'+str(num_unit)+'units_'+optimizer + ' optimizer_' + loss_ftn+' loss function')\n",
    "    f.write('\\n')\n",
    "    f.write('Year' + ','+ 'Month' + ',' + 'Ground')\n",
    "    for i in range(len_PRED):\n",
    "        f.write(','+ 'a'+str(i))\n",
    "    f.write('\\n')\n",
    "    \n",
    "    if Ouput_way is \"StepUp\":\n",
    "        for idx2 in range(0, len(testX)):        \n",
    "\n",
    "            pred = []\n",
    "            pred_in = testX[idx2:idx2+1]  #    (1, 1, 96)            \n",
    "\n",
    "            for pred_n in range(len_PRED):\n",
    "                resultY = model.predict(pred_in)\n",
    "                pred.append(resultY)\n",
    "\n",
    "                pred_in = np.append(pred_in,resultY)\n",
    "                pred_in = pred_in[1:]\n",
    "                pred_in = pred_in.reshape(1, len_LSTM, 1)\n",
    "\n",
    "            date = str(Year) + ',' + str(Mon)\n",
    "            f.write(date)\n",
    "            f.write(',' + str(NowY[0][0]))\n",
    "\n",
    "            for nwr in range(len_PRED):\n",
    "                f.write(',' + str(pred[nwr][0][0]))   \n",
    "\n",
    "            f.write('\\n')\n",
    "            pred_in = []\n",
    "            resultY = []\n",
    "            print(idx2)\n",
    "\n",
    "        f.close()\n",
    "                  \n",
    "    \n",
    "    if Output_way is \"OneTime\":\n",
    "        for idx2 in range(0, len(testX)):\n",
    "\n",
    "            NowY = testNowY[idx2:idx2+1]\n",
    "\n",
    "            Year = testYear[idx2][0]\n",
    "            Mon = testMon[idx2][0]\n",
    "\n",
    "            pred = []\n",
    "            pred_in = testX[idx2:idx2+1]      \n",
    "\n",
    "            resultY = model.predict(pred_in)\n",
    "\n",
    "            date = str(Year) + ',' + str(Mon)\n",
    "            f.write(date)\n",
    "            f.write(',' + str(NowY[0][0]))\n",
    "\n",
    "            for nwr in range(len_PRED):\n",
    "                f.write(',' + str(resultY[0][nwr]))   \n",
    "\n",
    "            f.write('\\n')\n",
    "            pred_in = []\n",
    "            resultY = []\n",
    "            print(idx2)\n",
    "\n",
    "        f.close()\n",
    "            \n",
    "\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output :  StepUp\n",
      "allDataSet:  (3102, 135)\n",
      "allDataSet_size:  3102\n",
      "allDataSet Type:  <class 'pandas.core.frame.DataFrame'>\n",
      "allDataSet_size Type:  <class 'int'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['b99' 'b98' 'b97' 'b96' 'b95' 'b94' 'b93' 'b92' 'b91' 'b90' 'b89' 'b88'\\n 'b87' 'b86' 'b85' 'b84' 'b83' 'b82' 'b81' 'b80' 'b79' 'b78' 'b77' 'b76'\\n 'b75' 'b74' 'b73'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-59e913609955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m Make_LSTM_SSN(2856, 144, 1, \"StepUp\", state_condition='Stateful', shuffle='False', \n\u001b[1;32m----> 2\u001b[1;33m               pred_hour=132, LSTM_hour=132, num_unit=240, num_epoch=1200, optimizer='Adam', loss_ftn='mean_squared_error')\n\u001b[0m\u001b[0;32m      3\u001b[0m Make_LSTM_SSN(2856, 144, 1, \"StepUp\", state_condition='Stateful', shuffle='False', \n\u001b[0;32m      4\u001b[0m               pred_hour=132, LSTM_hour=264, num_unit=240, num_epoch=1200, optimizer='Adam', loss_ftn='mean_squared_error')\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-244919c3079c>\u001b[0m in \u001b[0;36mMake_LSTM_SSN\u001b[1;34m(train_index, val_index, test_index, Output_Type, state_condition, shuffle, pred_hour, LSTM_hour, num_unit, num_epoch, optimizer, loss_ftn)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mflux1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallDataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLSTM_title1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mflux2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallDataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLSTM_title2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mflux3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallDataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLSTM_title3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mflux4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallDataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLSTM_title4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['b99' 'b98' 'b97' 'b96' 'b95' 'b94' 'b93' 'b92' 'b91' 'b90' 'b89' 'b88'\\n 'b87' 'b86' 'b85' 'b84' 'b83' 'b82' 'b81' 'b80' 'b79' 'b78' 'b77' 'b76'\\n 'b75' 'b74' 'b73'] not in index\""
     ]
    }
   ],
   "source": [
    "Make_LSTM_SSN(2856, 144, 1, \"StepUp\", state_condition='Stateful', shuffle='False', \n",
    "              pred_hour=132, LSTM_hour=132, num_unit=240, num_epoch=1200, optimizer='Adam', loss_ftn='mean_squared_error')\n",
    "Make_LSTM_SSN(2856, 144, 1, \"StepUp\", state_condition='Stateful', shuffle='False', \n",
    "              pred_hour=132, LSTM_hour=264, num_unit=240, num_epoch=1200, optimizer='Adam', loss_ftn='mean_squared_error')\n",
    "    \n",
    "Make_LSTM_SSN(2856, 144, 1, \"StepUp\", state_condition='Stateful', shuffle='False', \n",
    "              pred_hour=132, LSTM_hour=132, num_unit=240, num_epoch=600, optimizer='Adam', loss_ftn='mean_squared_error')\n",
    "Make_LSTM_SSN(2856, 144, 1, \"StepUp\", state_condition='Stateful', shuffle='False', \n",
    "              pred_hour=132, LSTM_hour=132, num_unit=480, num_epoch=1200, optimizer='Adam', loss_ftn='mean_squared_error')\n",
    "Make_LSTM_SSN(2856, 144, 1, \"StepUp\", state_condition='Stateful', shuffle='False', \n",
    "              pred_hour=132, LSTM_hour=132, num_unit=480, num_epoch=600, optimizer='Adam', loss_ftn='mean_squared_error')\n",
    "\n",
    "## 1998~2009 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
